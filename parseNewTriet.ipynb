{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3 as lite\n",
    "from sqlite3 import Error\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "import matplotlib.ticker as tick\n",
    "import requests\n",
    "import difflib as diff\n",
    "import re\n",
    "import csv\n",
    "import ast\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "# Check the length of the code after tokenization\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language = \"Java\"\n",
    "language = \"TypeScript\"\n",
    "b_remove_comments = True\n",
    "b_shrink_indentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 3, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "def quicksort(arr):\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "    pivot = arr[len(arr) // 2]\n",
    "    left = [x for x in arr if x < pivot]\n",
    "    middle = [x for x in arr if x == pivot]\n",
    "    right = [x for x in arr if x > pivot]\n",
    "    return quicksort(left) + middle + quicksort(right)\n",
    "\n",
    "# Example usage:\n",
    "arr = [3, 6, 8, 10, 1, 2, 1]\n",
    "print(quicksort(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_name = {\"JavaScript\": \"JS\", \"Python\": \"PY\", \"TypeScript\": \"TS\", \"CPP\": \"CPP\", \"C\": \"C\", \"Java\": \"JAVA\", \"C#\": \"CS\"}\n",
    "sname = short_name[language]\n",
    "path_dict = {\n",
    "    \"JavaScript\": \"/hpcfs/users/a1232991/Data/CVESingle/CVE_JS/JavaScript_data.parquet\",\n",
    "    \"Python\": \"/hpcfs/users/a1232991/Data/CVESingle/CVE_PY/Python_data.parquet\",\n",
    "    \"TypeScript\": \"/hpcfs/users/a1232991/Data/CVESingle/CVE_TS/TypeScript_data.parquet\",\n",
    "    \"CPP\": \"/hpcfs/users/a1232991/Data/CVESingle/CVE_CPP/C++_data.parquet\",\n",
    "    \"C\": \"/hpcfs/users/a1232991/Data/CVESingle/CVE_C/C_data.parquet\",\n",
    "    \"Java\": \"/hpcfs/users/a1232991/Data/CVESingle/CVE_JAVA/Java_data.parquet\",\n",
    "    \"C#\": \"/hpcfs/users/a1232991/Data/CVESingle/CVE_CS/C#_data.parquet\"\n",
    "}\n",
    "\n",
    "df_codes = pd.read_parquet(path_dict[language], engine='pyarrow')\n",
    "# df_codes = df_codes[df_codes['before_change']=='True']\n",
    "# df_codes = df_codes[df_codes['added_only']=='True']\n",
    "df_codes = df_codes[[\"repo_url\", \"hash\", \"code\", \"label\", 'added_only', 'mod_lines']]\n",
    "df_codes.columns = ['repo_url', 'hash', 'code_before', 'target', 'added_only', 'mod_lines']\n",
    "df_codes['commit_url'] = df_codes.apply(lambda x: x['repo_url'].replace(\".git\", \"\") + '/commit/'+x['hash'], axis=1)\n",
    "# convert label to int\n",
    "df_codes['target'] = df_codes['target'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/hpcfs/users/a1232991/Vuldetect/VulDetect/linevul/parseNewTriet.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bp2-log-1.hpc.adelaide.edu.au/hpcfs/users/a1232991/Vuldetect/VulDetect/linevul/parseNewTriet.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39m265\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bp2-log-1.hpc.adelaide.edu.au/hpcfs/users/a1232991/Vuldetect/VulDetect/linevul/parseNewTriet.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(df_codes[df_codes[\u001b[39m'\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m==\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49miloc[idx][\u001b[39m'\u001b[39m\u001b[39mcode_before\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bp2-log-1.hpc.adelaide.edu.au/hpcfs/users/a1232991/Vuldetect/VulDetect/linevul/parseNewTriet.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(df_codes[df_codes[\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39miloc[idx][\u001b[39m'\u001b[39m\u001b[39mmod_lines\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bp2-log-1.hpc.adelaide.edu.au/hpcfs/users/a1232991/Vuldetect/VulDetect/linevul/parseNewTriet.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(df_codes[df_codes[\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39miloc[idx][\u001b[39m'\u001b[39m\u001b[39madded_only\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m/hpcfs/users/a1232991/local/virtualenvs/llm/lib/python3.9/site-packages/pandas/core/indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1100\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1102\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m-> 1103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/hpcfs/users/a1232991/local/virtualenvs/llm/lib/python3.9/site-packages/pandas/core/indexing.py:1656\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1653\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index by location index with a non-integer key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1655\u001b[0m \u001b[39m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1656\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_integer(key, axis)\n\u001b[1;32m   1658\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_ixs(key, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[0;32m/hpcfs/users/a1232991/local/virtualenvs/llm/lib/python3.9/site-packages/pandas/core/indexing.py:1589\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1587\u001b[0m len_axis \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1588\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m len_axis \u001b[39mor\u001b[39;00m key \u001b[39m<\u001b[39m \u001b[39m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1589\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msingle positional indexer is out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "idx = 265\n",
    "print(df_codes[df_codes['target']==1].iloc[idx]['code_before'])\n",
    "print(df_codes[df_codes['target']==1].iloc[idx]['mod_lines'])\n",
    "print(df_codes[df_codes['target']==1].iloc[idx]['added_only'])\n",
    "print(df_codes[df_codes['target']==1].iloc[idx]['commit_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = df_codes[df_codes['target']==\"1\"].iloc[idx:idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAW_TAG_SYMBOL = '\\u25C6'\n",
    "# POSITION = 'BEGIN'\n",
    "# idx = 0\n",
    "\n",
    "# df_test = df_test.apply(insert_tag, axis=1)\n",
    "# df_test['code_before'] = df_test['code_before'].apply(lambda x: parser.clean(x))\n",
    "# df_test = df_test.apply(remove_tag_and_generate_mod_lines, axis=1)\n",
    "\n",
    "# print(df_test[df_test['target']==\"1\"].iloc[idx]['code_before'])\n",
    "# print(df_test[df_test['target']==\"1\"].iloc[idx]['mod_lines'])\n",
    "# print(df_test[df_test['target']==\"1\"].iloc[idx]['added_only'])\n",
    "# print(df_test[df_test['target']==\"1\"].iloc[idx]['commit_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAW_TAG_SYMBOL = '## FLAW_LINE_TAG ##'\n",
    "# POSITION = 'END'\n",
    "    \n",
    "# # df_test = df_test.apply(insert_tag, axis=1)\n",
    "# # df_test['code_before'] = df_test['code_before'].apply(auto_shrink_indentation)\n",
    "# df_test = df_test.apply(remove_tag_and_generate_mod_lines, axis=1)\n",
    "\n",
    "# print(df_test[df_test['target']==\"1\"].iloc[idx]['code_before'])\n",
    "# print(df_test[df_test['target']==\"1\"].iloc[idx]['mod_lines'])\n",
    "# print(df_test[df_test['target']==\"1\"].iloc[idx]['added_only'])\n",
    "# print(df_test[df_test['target']==\"1\"].iloc[idx]['commit_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_url</th>\n",
       "      <th>hash</th>\n",
       "      <th>code_before</th>\n",
       "      <th>target</th>\n",
       "      <th>added_only</th>\n",
       "      <th>mod_lines</th>\n",
       "      <th>commit_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/uzbl/uzbl.git</td>\n",
       "      <td>1958b52d41cba96956dc1995660de49525ed1047</td>\n",
       "      <td>eval_js(WebKitWebView * web_view, gchar *scrip...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4,17,18,19,20,21,22,40,41,42</td>\n",
       "      <td>https://github.com/uzbl/uzbl/commit/1958b52d41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>https://github.com/memcached/memcached.git</td>\n",
       "      <td>75cc83685e103bc8ba380a57468c8f04413033f9</td>\n",
       "      <td>static int try_read_command(conn *c) {\\n    as...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>89</td>\n",
       "      <td>https://github.com/memcached/memcached/commit/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>https://github.com/memcached/memcached.git</td>\n",
       "      <td>75cc83685e103bc8ba380a57468c8f04413033f9</td>\n",
       "      <td>static enum try_read_result try_read_network(c...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>https://github.com/memcached/memcached/commit/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>https://github.com/memcached/memcached.git</td>\n",
       "      <td>d9cd01ede97f4145af9781d448c62a3318952719</td>\n",
       "      <td>static int try_read_command(conn *c) {\\n    as...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>101</td>\n",
       "      <td>https://github.com/memcached/memcached/commit/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>https://github.com/memcached/memcached.git</td>\n",
       "      <td>a8c4a82787b8b6c256d61bd5c42fb7f92d1bae00</td>\n",
       "      <td>static inline void process_get_command(conn *c...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>https://github.com/memcached/memcached/commit/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>https://github.com/memcached/memcached.git</td>\n",
       "      <td>dbb7a8af90054bf4ef51f5814ef7ceb17d83d974</td>\n",
       "      <td>static void settings_init(void) {\\n    setting...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>https://github.com/memcached/memcached/commit/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>https://github.com/memcached/memcached.git</td>\n",
       "      <td>554b56687a19300a75ec24184746b5512580c819</td>\n",
       "      <td>static inline void get_conn_text(const conn *c...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>33,34</td>\n",
       "      <td>https://github.com/memcached/memcached/commit/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>https://github.com/uclouvain/openjpeg.git</td>\n",
       "      <td>5d00b719f4b93b1445e6fb4c766b9a9883c57949</td>\n",
       "      <td>void opj_get_all_encoding_parameters(   const ...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>42,43,44,45</td>\n",
       "      <td>https://github.com/uclouvain/openjpeg/commit/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>https://github.com/uclouvain/openjpeg.git</td>\n",
       "      <td>5d00b719f4b93b1445e6fb4c766b9a9883c57949</td>\n",
       "      <td>static INLINE OPJ_BOOL opj_tcd_init_tile(opj_t...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>46,47,48,49</td>\n",
       "      <td>https://github.com/uclouvain/openjpeg/commit/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>https://github.com/uclouvain/openjpeg.git</td>\n",
       "      <td>940100c28ae28931722290794889cf84a92c5f6f</td>\n",
       "      <td>static OPJ_BOOL opj_j2k_write_mco(     opj_j2k...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>17,18,44,47</td>\n",
       "      <td>https://github.com/uclouvain/openjpeg/commit/9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       repo_url  \\\n",
       "0              https://github.com/uzbl/uzbl.git   \n",
       "134  https://github.com/memcached/memcached.git   \n",
       "135  https://github.com/memcached/memcached.git   \n",
       "299  https://github.com/memcached/memcached.git   \n",
       "388  https://github.com/memcached/memcached.git   \n",
       "497  https://github.com/memcached/memcached.git   \n",
       "655  https://github.com/memcached/memcached.git   \n",
       "847   https://github.com/uclouvain/openjpeg.git   \n",
       "867   https://github.com/uclouvain/openjpeg.git   \n",
       "903   https://github.com/uclouvain/openjpeg.git   \n",
       "\n",
       "                                         hash  \\\n",
       "0    1958b52d41cba96956dc1995660de49525ed1047   \n",
       "134  75cc83685e103bc8ba380a57468c8f04413033f9   \n",
       "135  75cc83685e103bc8ba380a57468c8f04413033f9   \n",
       "299  d9cd01ede97f4145af9781d448c62a3318952719   \n",
       "388  a8c4a82787b8b6c256d61bd5c42fb7f92d1bae00   \n",
       "497  dbb7a8af90054bf4ef51f5814ef7ceb17d83d974   \n",
       "655  554b56687a19300a75ec24184746b5512580c819   \n",
       "847  5d00b719f4b93b1445e6fb4c766b9a9883c57949   \n",
       "867  5d00b719f4b93b1445e6fb4c766b9a9883c57949   \n",
       "903  940100c28ae28931722290794889cf84a92c5f6f   \n",
       "\n",
       "                                           code_before  target added_only  \\\n",
       "0    eval_js(WebKitWebView * web_view, gchar *scrip...       1      False   \n",
       "134  static int try_read_command(conn *c) {\\n    as...       1      False   \n",
       "135  static enum try_read_result try_read_network(c...       1      False   \n",
       "299  static int try_read_command(conn *c) {\\n    as...       1      False   \n",
       "388  static inline void process_get_command(conn *c...       1      False   \n",
       "497  static void settings_init(void) {\\n    setting...       1      False   \n",
       "655  static inline void get_conn_text(const conn *c...       1      False   \n",
       "847  void opj_get_all_encoding_parameters(   const ...       1      False   \n",
       "867  static INLINE OPJ_BOOL opj_tcd_init_tile(opj_t...       1      False   \n",
       "903  static OPJ_BOOL opj_j2k_write_mco(     opj_j2k...       1      False   \n",
       "\n",
       "                        mod_lines  \\\n",
       "0    4,17,18,19,20,21,22,40,41,42   \n",
       "134                            89   \n",
       "135                             3   \n",
       "299                           101   \n",
       "388                            23   \n",
       "497                             4   \n",
       "655                         33,34   \n",
       "847                   42,43,44,45   \n",
       "867                   46,47,48,49   \n",
       "903                   17,18,44,47   \n",
       "\n",
       "                                            commit_url  \n",
       "0    https://github.com/uzbl/uzbl/commit/1958b52d41...  \n",
       "134  https://github.com/memcached/memcached/commit/...  \n",
       "135  https://github.com/memcached/memcached/commit/...  \n",
       "299  https://github.com/memcached/memcached/commit/...  \n",
       "388  https://github.com/memcached/memcached/commit/...  \n",
       "497  https://github.com/memcached/memcached/commit/...  \n",
       "655  https://github.com/memcached/memcached/commit/...  \n",
       "847  https://github.com/uclouvain/openjpeg/commit/5...  \n",
       "867  https://github.com/uclouvain/openjpeg/commit/5...  \n",
       "903  https://github.com/uclouvain/openjpeg/commit/9...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes[df_codes['mod_lines'] != ''].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicate codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop duplicates:  (200413, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before drop duplicates: \", df_codes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by 'label' in descending order\n",
    "df_codes = df_codes.sort_values(by='target', ascending=False)\n",
    "\n",
    "df_codes.drop_duplicates(subset=['code_before'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After drop duplicates:  (134226, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"After drop duplicates: \", df_codes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add tags of flaw lines to the code in order to recover in the later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "FLAW_TAG_SYMBOL = '\\u25C6'\n",
    "POSITION = 'BEGIN'\n",
    "\n",
    "def insert_tag(brow):\n",
    "    row = brow.copy()\n",
    "    # insert a rare token after the first no-space character to indicate the lines tagged by mod_lines in the code\n",
    "    if row['mod_lines'] != '':\n",
    "        mod_lines = row['mod_lines'].split(',')\n",
    "        code = row['code_before']\n",
    "        code = code.split('\\n')\n",
    "        for line in mod_lines:\n",
    "            line = int(line)\n",
    "            if POSITION == 'BEGIN':\n",
    "                code[line] = re.sub(r\"^(\\s*\\S)\", fr\"\\1{FLAW_TAG_SYMBOL}\", code[line])\n",
    "            else:\n",
    "                code[line] = code[line] + FLAW_TAG_SYMBOL\n",
    "\n",
    "        code = '\\n'.join(code)\n",
    "        row['code_before'] = code\n",
    "    return row\n",
    "\n",
    "def remove_tag_and_generate_mod_lines(brow):\n",
    "    row = brow.copy()\n",
    "    # remove the rare token and generate mod_lines\n",
    "    pattern = fr\"^(\\s*\\S)\\s*{FLAW_TAG_SYMBOL}\"\n",
    "    \n",
    "    code = row['code_before']\n",
    "    code = code.split('\\n')\n",
    "    mod_lines = []\n",
    "    for i in range(len(code)):\n",
    "        if bool(re.search(FLAW_TAG_SYMBOL, code[i])):\n",
    "            if POSITION == \"BEGIN\":\n",
    "                code[i] = re.sub(pattern, r\"\\1\", code[i])\n",
    "            else:\n",
    "                code[i] = code[i].replace(FLAW_TAG_SYMBOL, \"\")\n",
    "            mod_lines.append(str(i))\n",
    "\n",
    "    row['code_before'] = '\\n'.join(code)\n",
    "    row['mod_lines'] = ','.join(mod_lines)\n",
    "\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistic the token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token length:\n",
      "count    134226.000000\n",
      "mean        568.429753\n",
      "std        1637.260024\n",
      "min           2.000000\n",
      "25%         107.000000\n",
      "50%         231.000000\n",
      "75%         531.000000\n",
      "max      146722.000000\n",
      "Name: token_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_codes['token_length'] = df_codes['code_before'].apply(lambda x: len(tokenizer.encode(x)))\n",
    "print(\"Token length:\")\n",
    "print(df_codes['token_length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove comments in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_sitter import Language, Parser\n",
    "\n",
    "\n",
    "class TSParse:\n",
    "    r'''Parse C/C++ code using tree-sitter AST.\n",
    "    Example:\n",
    "    code = \"\"\"\n",
    "        #include \"ap_config.h\"\n",
    "        using namespace ContosoData;\\n\n",
    "        int main() {\n",
    "            int a = 1; // comment\n",
    "            /* comment // comment /*\n",
    "            int r += 4;\n",
    "            here */ int c = 2;\n",
    "            int d = 4;\n",
    "            int b /* comment */ = 2;\n",
    "            int e = 5;\n",
    "        }\n",
    "    \"\"\"\n",
    "    print(TSParse(\"./treesitter_c_cpp.so\").noisy(code, \"cpp\", True))\n",
    "    '''\n",
    "    noisy_query = {}\n",
    "    noisy_query[\"cpp\"] = \"\"\"\n",
    "            (comment) @comment\n",
    "            (preproc_include) @include\n",
    "            (using_declaration) @using\n",
    "        \"\"\"\n",
    "    noisy_query[\"c\"] = \"(comment) @comment (preproc_include) @include\"\n",
    "    noisy_query[\"python\"] = \"\"\"\n",
    "        (comment) @comment\n",
    "        (expression_statement \n",
    "            (string) @matched-string)\n",
    "        \"\"\"\n",
    "    noisy_query[\"java\"] = \"(line_comment) @linecomment (block_comment) @blockcomment\"\n",
    "    noisy_query[\"default\"] = \"(comment) @comment\"\n",
    "\n",
    "    def __init__(self, lang):\n",
    "        \"\"\"Initialize Tree-Sitter parsers.\"\"\"\n",
    "        lang = lang.lower()\n",
    "        assert lang in [\"c\", \"cpp\", \"python\", \"java\", \"javascript\", \"typescript\", \"c#\"], \"Language must be C/C++/Python/Java/JavaScript/TypeScript/C#\"\n",
    "        if lang == \"c#\":\n",
    "            lang = \"c_sharp\"\n",
    "        \n",
    "        self.lang = lang\n",
    "        self.parser_lang = Language('/hpcfs/users/a1232991/Data/my-languages.so', lang)\n",
    "        self.parser = Parser()\n",
    "        self.parser.set_language(self.parser_lang)\n",
    "\n",
    "    def query(self, code, query):\n",
    "        \"\"\"Run query on code.\"\"\"\n",
    "        # Get AST\n",
    "        tree = self.parser.parse(bytes(code, \"utf8\"))\n",
    "\n",
    "        # Return results\n",
    "        results = self.parser_lang.query(query).captures(tree.root_node)\n",
    "        # print(results)\n",
    "        return results\n",
    "\n",
    "    def clean(self, code):\n",
    "        \"\"\"Remove comments and includes from code.\n",
    "        Args:\n",
    "            code (str): Code as a string with newlines\n",
    "            lang (str): Can be C or C++\n",
    "        \"\"\"\n",
    "\n",
    "        # Find comments and includes\n",
    "        noisy_query = self.noisy_query[self.lang] if self.lang in self.noisy_query.keys() else self.noisy_query[\"default\"]\n",
    "        results = self.query(code, noisy_query)\n",
    "\n",
    "        # Remove comments and includes based on string slicing\n",
    "        code_new = code.splitlines()\n",
    "        for i in results:\n",
    "            sline, schar = i[0].start_point\n",
    "            eline, echar = i[0].end_point\n",
    "            # print('I=', i)\n",
    "            if sline == eline:\n",
    "                code_new[sline] = code_new[sline][:schar] + code_new[sline][echar:]\n",
    "            else:\n",
    "                for line_index in range(sline, min(len(code_new), eline + 1)):\n",
    "                    if line_index == sline:\n",
    "                        code_new[sline] = code_new[sline][:schar]\n",
    "                    elif line_index == eline:\n",
    "                        code_new[eline] = code_new[eline][echar:]\n",
    "                    else:\n",
    "                        code_new[line_index] = \"\"\n",
    "\n",
    "        # Filter out empty lines\n",
    "        non_empty_lines = [line for line in code_new if line.strip() != '']\n",
    "\n",
    "        # Rejoin the non-empty lines to form cleaned code\n",
    "        code_new = '\\n'.join(non_empty_lines)\n",
    "        \n",
    "        return code_new\n",
    "        \n",
    "        \n",
    "c_code = \"\"\"#include \"ap_config.h\"\n",
    "using namespace ContosoData;\n",
    "\n",
    "int main() { //comment\n",
    "    int a = 1; // comment\n",
    "    /* comment // comment /*\n",
    "    int r += 4;\n",
    "    here */ int c = 2;\n",
    "    int d = 4;\n",
    "    int b /* comment */ = 2;\n",
    "    int e = 5;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "python_code = \"\"\"\n",
    "'''ApexCodeUtility\n",
    "    afaf\n",
    "    aprint(\"Hello, #world!\")  # This is a comment\n",
    "    '''\n",
    "def my_function():\n",
    "                '''ApexCodeUtility\n",
    "                afaf\n",
    "                aprint(\"Hello, #world!\")  # This is a comment\n",
    "                '''\n",
    "                print(\"Hello, #world!\")  # This is a comment\n",
    "                '''ApexCodeUtility\n",
    "                afaf\n",
    "                aprint(\"Hello, #world!\")  # This is a comment\n",
    "                '''\n",
    "                x = \"hello\"\n",
    "                y = \"auto_shrink_indentation\n",
    "                afafaf\"\n",
    "                x = 42  # Another comment\n",
    "                # This line is a comment\n",
    "                # This line is a comment\n",
    "                # This line is a comment\n",
    "\"\"\"\n",
    "\n",
    "ts_code = \"\"\"\n",
    "case ts.SyntaxKind.VariableStatement:\n",
    "            case ts.SyntaxKind.TypeAliasDeclaration:\n",
    "            case ts.SyntaxKind.FunctionDeclaration:\n",
    "            case ts.SyntaxKind.ModuleDeclaration:\n",
    "                stop = visitor(node);\n",
    "        }\n",
    "        // if (node.kind !== ts.SyntaxKind.SourceFile) {\n",
    "        // \tif (getNodeText(sourceFile, node).indexOf('SymbolKind') >= 0) {\n",
    "        // \t\tconsole.log('FOUND TEXT IN NODE: ' + ts.SyntaxKind[node.kind]);\n",
    "        // \t\tconsole.log(getNodeText(sourceFile, node));\n",
    "        // \t}\n",
    "        // }\n",
    "        if (stop) {\n",
    "            return;\n",
    "        }\n",
    "        ts.forEachChild(node, visit);\n",
    "    };\n",
    "    visit(sourceFile);\n",
    "\"\"\"\n",
    "\n",
    "java_code = \"\"\"\n",
    "public class LowerTriangular    \n",
    "{    \n",
    "    public static void main(String[] args) {    \n",
    "    int rows, cols;   \n",
    "    /*\n",
    "    afaf\n",
    "    afaf\n",
    "    */\n",
    "    //Initialize matrix a    \n",
    "        int a[][] = {       \n",
    "                        {1, 2, 3},    \n",
    "                        {8, 6, 4},    \n",
    "                        {4, 5, 6}    \n",
    "                    };    \n",
    "              \n",
    "          //Calculates number of rows and columns present in given matrix    \n",
    "          rows = a.length;    \n",
    "          cols = a[0].length;    \n",
    "            \n",
    "          if(rows != cols){    \n",
    "              System.out.println(\"Matrix should be a square matrix\");    \n",
    "          }    \n",
    "          else {    \n",
    "              //Performs required operation to convert given matrix into lower triangular matrix    \n",
    "              System.out.println(\"Lower triangular matrix: \");    \n",
    "              for(int i = 0; i < rows; i++){    \n",
    "                  for(int j = 0; j < cols; j++){    \n",
    "                    if(j > i)    \n",
    "                      System.out.print(\"0 \");    \n",
    "                    else    \n",
    "                      System.out.print(a[i][j] + \" \");    \n",
    "                }    \n",
    "                System.out.println();    \n",
    "            }    \n",
    "        }    \n",
    "    }    \n",
    "}    \"\"\"\n",
    "\n",
    "\n",
    "parser = TSParse(language)\n",
    "# parser = TSParse(\"python\")\n",
    "# clean_code = parser.clean(python_code)\n",
    "\n",
    "# print(clean_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing comments\n",
      "count    134226.000000\n",
      "mean        522.627293\n",
      "std        1526.387956\n",
      "min           2.000000\n",
      "25%         103.000000\n",
      "50%         218.000000\n",
      "75%         486.000000\n",
      "max      143832.000000\n",
      "Name: token_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "if b_remove_comments:\n",
    "    df_codes = df_codes.apply(insert_tag, axis=1)\n",
    "    df_codes['code_before'] = df_codes['code_before'].apply(lambda x: parser.clean(x))\n",
    "    df_codes = df_codes.apply(remove_tag_and_generate_mod_lines, axis=1)\n",
    "    print(\"After removing comments\")\n",
    "    df_codes['token_length'] = df_codes['code_before'].apply(lambda x: len(tokenizer.encode(x)))\n",
    "    print(df_codes['token_length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shrink the indentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not in use\n",
    "import re\n",
    "\n",
    "def code_format(row):\n",
    "    name = f\"{random.getrandbits(128)}.py\"\n",
    "    x = x.strip()\n",
    "    with open(name, 'w') as f:\n",
    "        f.write(x)\n",
    "    \n",
    "    # execute black through command line\n",
    "    os.system(f\"black {name}\")\n",
    "\n",
    "    # read back the formatted code\n",
    "    with open(name, 'r') as f:\n",
    "        x = f.read()\n",
    "    os.remove(name)\n",
    "    return x\n",
    "\n",
    "def replace_whitespace(text):\n",
    "    text = text.strip()\n",
    "    return re.sub(r'\\s+', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def foo():\n",
      " if True:\n",
      "  print \"Hello\" \n",
      "  if False:\n",
      "   print(\"Nested\")\n",
      " print(\"World\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import black\n",
    "import textwrap\n",
    "import re\n",
    "import autopep8\n",
    "\n",
    "def format_indentation(code):\n",
    "    # Remove common leading whitespace\n",
    "    code = textwrap.dedent(code)\n",
    "    unit=' '\n",
    "\n",
    "    try:\n",
    "        code = black.format_str(code, mode=black.FileMode())\n",
    "    except Exception as e:\n",
    "        formatted_code = autopep8.fix_code(code)\n",
    "        # try:\n",
    "        #     code = convert_to_python3(code)\n",
    "        #     code = black.format_str(code, mode=black.FileMode())\n",
    "        # except:\n",
    "        #     print(\"Error in conversion:\", e, \"code:\", code)\n",
    "        #     return None\n",
    "    \n",
    "    # Adjust the indentation level\n",
    "    def adjust_indent(match):\n",
    "        # For every 4 spaces, add a single unit\n",
    "        return unit * (len(match.group(0)) // 4)\n",
    "\n",
    "    # Replace every multiple of 4 spaces with the corresponding number of units\n",
    "    formatted_code = re.sub(r'^( {4})+', adjust_indent, code, flags=re.MULTILINE)\n",
    "\n",
    "    return formatted_code\n",
    "\n",
    "\n",
    "# Test\n",
    "python2_code = \"\"\"\n",
    "    def my_function():\n",
    "            print \"Hello World\"\n",
    "\"\"\"\n",
    "\n",
    "# Test\n",
    "code = \"\"\"\n",
    "def foo():\n",
    "    if True:\n",
    "        print \"Hello\" \n",
    "        if False:\n",
    "            print(\"Nested\")\n",
    "    print(\"World\")\n",
    "\"\"\"\n",
    "\n",
    "print(format_indentation(code))\n",
    "\n",
    "# formatted_code = black.format_str(code, mode=black.FileMode())\n",
    "# print(formatted_code)\n",
    "\n",
    "# python3_code = convert_to_python3(python2_code)\n",
    "# print(python3_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from math import gcd\n",
    "\n",
    "def auto_shrink_indentation(code):\n",
    "    code = code.strip()\n",
    "    lines = code.split('\\n')\n",
    "\n",
    "    # Determine the indentation type (space or tab)\n",
    "    space_indent_count = []\n",
    "    tab_indent_count = []\n",
    "    for line in lines:\n",
    "        if line.startswith(' '):\n",
    "            space_indent_count.append(len(re.match(r'^[ ]*', line).group()))\n",
    "        elif line.startswith('\\t'):\n",
    "            tab_indent_count.append(len(re.match(r'^[\\t]*', line).group()))\n",
    "\n",
    "    indent_count = space_indent_count if len(space_indent_count) > 0 else tab_indent_count\n",
    "    using_tabs = len(tab_indent_count) > 0\n",
    "    # Calculate the greatest common divisor (GCD) of indentation quantities\n",
    "\n",
    "    if len(indent_count) == 0:\n",
    "        return code\n",
    "\n",
    "    if language == \"Python\":\n",
    "        # min_positive = min(x for x in indent_count if x > 0)\n",
    "        # if min_positive == 2:\n",
    "        #     indent_count = [x - x % 2 for x in indent_count]\n",
    "        # else:\n",
    "        #     indent_count = [x - x % 4 for x in indent_count]\n",
    "        # gcd_indent = indent_count[0]\n",
    "\n",
    "        # for num in indent_count[1:]:\n",
    "        #     if num > 0:\n",
    "        #         gcd_indent = gcd(gcd_indent, num)\n",
    "\n",
    "        # if gcd_indent == 0:\n",
    "        #     print(indent_count)\n",
    "        #     print(code)\n",
    "        # # print(\"GCD: \", gcd_indent)\n",
    "        # # Shrink the indentation by dividing by the GCD\n",
    "        # shrunk_lines = []\n",
    "        # for line in lines:\n",
    "        #     if line.startswith(' '):\n",
    "        #         indent_count = len(re.match(r'^[ ]*', line).group())\n",
    "        #         shrunk_indent_count = indent_count // gcd_indent\n",
    "        #         shrunk_line = ' ' * shrunk_indent_count + line[indent_count:]\n",
    "        #     elif line.startswith('\\t'):\n",
    "        #         indent_count = len(re.match(r'^[\\t]*', line).group())\n",
    "        #         shrunk_indent_count = indent_count // gcd_indent\n",
    "        #         shrunk_line = '\\t' * shrunk_indent_count + line[indent_count:]\n",
    "        #     else:\n",
    "        #         shrunk_line = line\n",
    "        #     shrunk_lines.append(shrunk_line)\n",
    "\n",
    "        # shrunk_code = '\\n'.join(shrunk_lines)\n",
    "        shrunk_code = format_indentation(code)\n",
    "    else:\n",
    "        if using_tabs:\n",
    "            # If using tabs, replace consecutive tabs at the start of a line with a single tab\n",
    "            shrunk_code = re.sub(r'^\\t+', '\\t', code, flags=re.MULTILINE)\n",
    "        else:\n",
    "            # If using spaces, replace consecutive spaces at the start of a line with a single space\n",
    "            shrunk_code = re.sub(r'^ +', ' ', code, flags=re.MULTILINE)\n",
    "\n",
    "    return shrunk_code\n",
    "\n",
    "# Example usage:\n",
    "original_code = \"\"\"\n",
    "def main():\n",
    " (opts, dummy) = parseArgs()\n",
    "\n",
    " if not os.path.exists(opts.destdir) and not opts.urls:\n",
    "  try:\n",
    "   os.makedirs(opts.destdir)\n",
    "  except OSError, e:\n",
    "   print >> sys.stderr, _(\"Error: Cannot create destination dir %s\") % opts.destdir\n",
    "   sys.exit(1)\n",
    "\n",
    " if not os.access(opts.destdir, os.W_OK) and not opts.urls:\n",
    "  print >> sys.stderr, _(\"Error: Cannot write to  destination dir %s\") % opts.destdir\n",
    "  sys.exit(1)\n",
    "\n",
    " my = RepoSync(opts=opts)\n",
    " my.doConfigSetup(fn=opts.config, init_plugins=opts.plugins)\n",
    "\n",
    " # Force unprivileged users to have a private temporary cachedir\n",
    " # if they've not given an explicit cachedir\n",
    " if os.getuid() != 0 and not opts.cachedir:\n",
    "  opts.tempcache = True\n",
    "\n",
    "\"\"\"\n",
    "# language = \"Java\"\n",
    "# original_code = convert_to_python3(original_code)\n",
    "# shrunken_code = auto_shrink_indentation(original_code)\n",
    "# code = convert_to_python3(original_code)\n",
    "# code = black.format_str(code, mode=black.FileMode())\n",
    "# print(format_indentation(original_code))\n",
    "\n",
    "# code_list = df_codes['code_before'].to_list()\n",
    "# for code in code_list:\n",
    "#     code = format_indentation(code)\n",
    "#     if code == None:\n",
    "#         break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After shrinking indentation\n",
      "count    134226.000000\n",
      "mean        423.933724\n",
      "std        1047.244801\n",
      "min           2.000000\n",
      "25%          96.000000\n",
      "50%         196.000000\n",
      "75%         423.000000\n",
      "max       84663.000000\n",
      "Name: token_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "if b_shrink_indentation:\n",
    "    if language == \"Python\":\n",
    "        FLAW_TAG_SYMBOL = '## FLAW_LINE_TAG ##'\n",
    "        POSITION = 'END'\n",
    "        \n",
    "    df_codes = df_codes.apply(insert_tag, axis=1)\n",
    "    df_codes['code_before'] = df_codes['code_before'].apply(auto_shrink_indentation)\n",
    "    df_codes = df_codes.apply(remove_tag_and_generate_mod_lines, axis=1)\n",
    "\n",
    "    df_codes['token_length'] = df_codes['code_before'].apply(lambda x: len(tokenizer.encode(x)))\n",
    "    print(\"After shrinking indentation\")\n",
    "    print(df_codes['token_length'].describe())\n",
    "# df_codes['code_before'] = df_codes['code_before'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514\n"
     ]
    }
   ],
   "source": [
    "# Sort the DataFrame in ascending order\n",
    "df_codes.sort_values(by='token_length', inplace=True)\n",
    "\n",
    "# Specify the desired percentage  RC&SI 93: 513 / None 82.4: 513\n",
    "desired_percentage = 80\n",
    "\n",
    "# Calculate the median index\n",
    "median_index = int((desired_percentage / 100) * len(df_codes))\n",
    "\n",
    "# Get the median value\n",
    "median_value = df_codes['token_length'].iloc[median_index]\n",
    "\n",
    "print(median_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whether remove the codes with token length > 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_codes = df_codes[(df_codes['added_only'] == \"False\") | (df_codes['token_length'] <= 512)]\n",
    "# df_codes = df_codes[df_codes['token_length'] <= 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     3301.000000\n",
       "mean      1030.276583\n",
       "std       2749.440791\n",
       "min         20.000000\n",
       "25%        204.000000\n",
       "50%        463.000000\n",
       "75%       1004.000000\n",
       "max      84663.000000\n",
       "Name: token_length, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes[df_codes['added_only'] == \"True\"]['token_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_url</th>\n",
       "      <th>hash</th>\n",
       "      <th>code_before</th>\n",
       "      <th>target</th>\n",
       "      <th>added_only</th>\n",
       "      <th>mod_lines</th>\n",
       "      <th>commit_url</th>\n",
       "      <th>token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154038</th>\n",
       "      <td>https://github.com/torvalds/linux.git</td>\n",
       "      <td>638164a2718f337ea224b747cf5977ef143166a4</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/torvalds/linux/commit/63816...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135611</th>\n",
       "      <td>https://github.com/torvalds/linux.git</td>\n",
       "      <td>82939d7999dfc1f1998c4b1c12e2f19edbdff272</td>\n",
       "      <td>}</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/torvalds/linux/commit/82939...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135607</th>\n",
       "      <td>https://github.com/torvalds/linux.git</td>\n",
       "      <td>82939d7999dfc1f1998c4b1c12e2f19edbdff272</td>\n",
       "      <td>#else</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/torvalds/linux/commit/82939...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179928</th>\n",
       "      <td>https://github.com/lldpd/lldpd.git</td>\n",
       "      <td>9221b5c249f9e4843f77c7f888d5705348d179c0</td>\n",
       "      <td>static void version_check(void) {}</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/lldpd/lldpd/commit/9221b5c2...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55987</th>\n",
       "      <td>https://github.com/tats/w3m.git</td>\n",
       "      <td>18dcbadf2771cdb0c18509b14e4e73505b242753</td>\n",
       "      <td>pcmap(void)\\n{\\n}</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>https://github.com/tats/w3m/commit/18dcbadf277...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     repo_url  \\\n",
       "154038  https://github.com/torvalds/linux.git   \n",
       "135611  https://github.com/torvalds/linux.git   \n",
       "135607  https://github.com/torvalds/linux.git   \n",
       "179928     https://github.com/lldpd/lldpd.git   \n",
       "55987         https://github.com/tats/w3m.git   \n",
       "\n",
       "                                            hash  \\\n",
       "154038  638164a2718f337ea224b747cf5977ef143166a4   \n",
       "135611  82939d7999dfc1f1998c4b1c12e2f19edbdff272   \n",
       "135607  82939d7999dfc1f1998c4b1c12e2f19edbdff272   \n",
       "179928  9221b5c249f9e4843f77c7f888d5705348d179c0   \n",
       "55987   18dcbadf2771cdb0c18509b14e4e73505b242753   \n",
       "\n",
       "                               code_before  target added_only mod_lines  \\\n",
       "154038                                           0      False             \n",
       "135611                                   }       0      False             \n",
       "135607                               #else       0      False             \n",
       "179928  static void version_check(void) {}       0      False             \n",
       "55987                    pcmap(void)\\n{\\n}       0      False             \n",
       "\n",
       "                                               commit_url  token_length  \n",
       "154038  https://github.com/torvalds/linux/commit/63816...             2  \n",
       "135611  https://github.com/torvalds/linux/commit/82939...             3  \n",
       "135607  https://github.com/torvalds/linux/commit/82939...             4  \n",
       "179928  https://github.com/lldpd/lldpd/commit/9221b5c2...            11  \n",
       "55987   https://github.com/tats/w3m/commit/18dcbadf277...            11  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcmap(void)\n",
      "{\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(df_codes.iloc[4]['code_before'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "static inline struct f2fs_sb_info *F2FS_P_SB(struct page *page)\n",
      "{\n",
      "\treturn F2FS_M_SB(page->mapping);\n",
      "}\n",
      "2\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "idx = 132\n",
    "print(df_codes[df_codes['target']==1].iloc[idx]['code_before'])\n",
    "print(df_codes[df_codes['target']==1].iloc[idx]['mod_lines'])\n",
    "print(df_codes[df_codes['target']==1].iloc[idx]['added_only'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/torvalds/linux.git/commit/638164a2718f337ea224b747cf5977ef143166a4'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes.iloc[0]['repo_url'] + '/commit/'+df_codes.iloc[0]['hash']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Any N/A lines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'flaw_lines' in df_codes.columns:\n",
    "#     df_flaw_index = df_codes.apply(\n",
    "#         lambda row: \",\".join([str(int(i) - int(row['start_line'])) for i in row['flaw_lines'].split(\",\")])\n",
    "#                     if row['target'] == 1 else -1,\n",
    "#         axis=1\n",
    "#     )\n",
    "\n",
    "#     # Update the flaw_index column in the DataFrame\n",
    "#     df_codes['flaw_index'] = df_flaw_index\n",
    "# else:\n",
    "#     df_codes['flaw_index'] = -1\n",
    "#     df_codes['flaw_lines'] = -1\n",
    "df_codes['flaw_index'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Train set shape: (107380, 5)\n",
      "Validation set shape: (13423, 5)\n",
      "Test set shape: (13423, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "df_python_align = df_codes[['code_before', 'target', 'mod_lines', 'flaw_index', 'commit_url']]\n",
    "df_python_align.columns = ['processed_func', 'target', 'flaw_line', 'flaw_line_index', 'commit_url']\n",
    "\n",
    "# Split the DataFrame into train and remaining\n",
    "train_df, remaining_df = train_test_split(df_python_align, test_size=0.2, random_state=1)\n",
    "\n",
    "# Split the remaining DataFrame into validation and test\n",
    "val_df, test_df = train_test_split(remaining_df, test_size=0.5, random_state=1)\n",
    "\n",
    "# Print the shapes of the resulting DataFrames\n",
    "print(\"Train set shape:\", train_df.shape)\n",
    "print(\"Validation set shape:\", val_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)\n",
    "\n",
    "train_df.to_csv(f\"/hpcfs/users/a1232991/Data/CVESingle/CVE_{sname}/CVE{language}_train2.csv\", index=None)\n",
    "val_df.to_csv(f\"/hpcfs/users/a1232991/Data/CVESingle/CVE_{sname}/CVE{language}_val2.csv\", index=None)\n",
    "test_df.to_csv(f\"/hpcfs/users/a1232991/Data/CVESingle/CVE_{sname}/CVE{language}_test2.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_code = \"\"\"\n",
    "writeToMethod(SWFBlock block, \n",
    "                           SWFByteOutputMethod method, void* data)\n",
    "{\n",
    "\tSWFOutput out = ((SWFShape)block)->out;\n",
    "\tSWFOutput_writeToMethod(out, method, data);\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 50118, 29631, 3972, 47967, 1640, 11871, 597, 38866, 1803, 6, 1437, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 8883, 597, 47447, 48293, 47967, 5448, 6, 13842, 3226, 414, 43, 50118, 45152, 50118, 50117, 11871, 7942, 1182, 9179, 66, 5457, 41006, 11871, 597, 45336, 43, 16776, 43, 46613, 995, 131, 50118, 50117, 11871, 7942, 1182, 9179, 1215, 29631, 3972, 47967, 1640, 995, 6, 5448, 6, 414, 4397, 50118, 24303, 50118, 2]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "results1 = tokenizer.encode(python_code)\n",
    "# print in one line\n",
    "print(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
