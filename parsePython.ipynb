{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hpcfs/users/a1232991/local/virtualenvs/llm/lib/python3.9/site-packages/codetf/tree-sitter-prebuilts/Linux\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3 as lite\n",
    "from sqlite3 import Error\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "import matplotlib.ticker as tick\n",
    "import requests\n",
    "import difflib as diff\n",
    "import re\n",
    "import csv\n",
    "import ast\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from codetf.code_utility.apex.apex_code_utility import ApexCodeUtility\n",
    "\n",
    "apex_code_utility = ApexCodeUtility()\n",
    "# from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"Python\"\n",
    "# language = \"TypeScript\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection(db_file):\n",
    "    \"\"\"\n",
    "    create a connection to sqlite3 database\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = lite.connect(db_file, timeout=10)  # connection via sqlite3\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['repo_url', 'hash', 'committer', 'committer_date', 'filename',\n",
    "    #    'programming_language', 'signature', 'code', 'label', 'before_change',\n",
    "    #    'added_only']\n",
    "short_name = {\"JavaScript\": \"JS\", \"Python\": \"PY\", \"TypeScript\": \"TS\", \"CPP\": \"CPP\", \"C\": \"C\", \"Java\": \"Java\", \"C#\": \"C#\"}\n",
    "sname = short_name[language]\n",
    "\n",
    "df_codes = pd.read_parquet(f'/hpcfs/users/a1232991/Data/CVESingle/CVE_{sname}/{sname.lower()}_data.parquet', engine='pyarrow')\n",
    "df_codes = df_codes[df_codes['before_change']=='True']\n",
    "df_codes = df_codes[[\"repo_url\", \"hash\", \"code\", \"label\"]]\n",
    "df_codes.columns = ['repo_url', 'hash', 'code_before', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_url</th>\n",
       "      <th>hash</th>\n",
       "      <th>code_before</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/latchset/kdcproxy.git</td>\n",
       "      <td>f274aa6787cb8b3ec1cc12c440a56665b7231882</td>\n",
       "      <td>def __call__(self, env, start_response):\\n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/latchset/kdcproxy.git</td>\n",
       "      <td>f274aa6787cb8b3ec1cc12c440a56665b7231882</td>\n",
       "      <td>def __filter_addr(self, addr):\\n        if...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/latchset/kdcproxy.git</td>\n",
       "      <td>f274aa6787cb8b3ec1cc12c440a56665b7231882</td>\n",
       "      <td>def sock_type(self, sock):\\n        try:\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/latchset/kdcproxy.git</td>\n",
       "      <td>f274aa6787cb8b3ec1cc12c440a56665b7231882</td>\n",
       "      <td>def __init__(self):\\n        self.__resolv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://github.com/latchset/kdcproxy.git</td>\n",
       "      <td>f274aa6787cb8b3ec1cc12c440a56665b7231882</td>\n",
       "      <td>def __str__(self):\\n        return \"%d %s\"...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   repo_url  \\\n",
       "0  https://github.com/latchset/kdcproxy.git   \n",
       "1  https://github.com/latchset/kdcproxy.git   \n",
       "2  https://github.com/latchset/kdcproxy.git   \n",
       "3  https://github.com/latchset/kdcproxy.git   \n",
       "4  https://github.com/latchset/kdcproxy.git   \n",
       "\n",
       "                                       hash  \\\n",
       "0  f274aa6787cb8b3ec1cc12c440a56665b7231882   \n",
       "1  f274aa6787cb8b3ec1cc12c440a56665b7231882   \n",
       "2  f274aa6787cb8b3ec1cc12c440a56665b7231882   \n",
       "3  f274aa6787cb8b3ec1cc12c440a56665b7231882   \n",
       "4  f274aa6787cb8b3ec1cc12c440a56665b7231882   \n",
       "\n",
       "                                         code_before target  \n",
       "0      def __call__(self, env, start_response):\\n...      1  \n",
       "1      def __filter_addr(self, addr):\\n        if...      0  \n",
       "2      def sock_type(self, sock):\\n        try:\\n...      0  \n",
       "3      def __init__(self):\\n        self.__resolv...      0  \n",
       "4      def __str__(self):\\n        return \"%d %s\"...      0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicate codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop duplicates:  (15217, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before drop duplicates: \", df_codes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by 'label' in descending order\n",
    "df_codes = df_codes.sort_values(by='target', ascending=False)\n",
    "\n",
    "df_codes.drop_duplicates(subset=['code_before'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After drop duplicates:  (13419, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"After drop duplicates: \", df_codes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove comments in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes['code_before'] = df_codes['code_before'].apply(lambda x: apex_code_utility.remove_comments(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = 'def iter_fields(node):\\\n",
    "    \"\"\"\"\"\"\\\n",
    "    Yield a tuple of ``(fieldname, value)`` for each field in ``node._fields``\\\n",
    "    that is present on *node*.\\\n",
    "    \"\"\"\"\"\"\\\n",
    "    for field in node._fields:\\\n",
    "        try:\\\n",
    "            yield field, getattr(node, field)\\\n",
    "        except AttributeError:\\\n",
    "            pass'\n",
    "\n",
    "after_code = apex_code_utility.remove_comments(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After remove comments:  def iter_fields(node):    \"\"\"\"\"\"    Yield a tuple of ``(fieldname, value)`` for each field in ``node._fields``    that is present on *node*.    \"\"\"\"\"\"    for field in node._fields:        try:            yield field, getattr(node, field)        except AttributeError:            pass\n"
     ]
    }
   ],
   "source": [
    "print(\"After remove comments: \", after_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    12442\n",
       "1      977\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not in use\n",
    "import re\n",
    "\n",
    "def code_format(row):\n",
    "    name = f\"{random.getrandbits(128)}.py\"\n",
    "    x = x.strip()\n",
    "    with open(name, 'w') as f:\n",
    "        f.write(x)\n",
    "    \n",
    "    # execute black through command line\n",
    "    os.system(f\"black {name}\")\n",
    "\n",
    "    # read back the formatted code\n",
    "    with open(name, 'r') as f:\n",
    "        x = f.read()\n",
    "    os.remove(name)\n",
    "    return x\n",
    "\n",
    "def replace_whitespace(text):\n",
    "    text = text.strip()\n",
    "    return re.sub(r'\\s+', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if language == 'Python':\n",
    "#     # pandarallel.initialize(progress_bar=True)\n",
    "#     # df_codes['code_before'] = df_codes['code_before'].apply(code_format)\n",
    "#     df_codes['code_before'] = df_codes['code_before'].apply(replace_whitespace)\n",
    "df_codes['code_before'] = df_codes['code_before'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the tokenized statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2408 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    13419.000000\n",
       "mean       326.884045\n",
       "std        634.483865\n",
       "min          9.000000\n",
       "25%         64.000000\n",
       "50%        147.000000\n",
       "75%        349.000000\n",
       "max      18221.000000\n",
       "Name: code_before, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the length of the code after tokenization\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "token_lengths = df_codes['code_before'].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "token_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def __call__(self, env, start_response):\\n        try:\\n            # Validate the method\\n            method = env[\"REQUEST_METHOD\"].upper()\\n            if method != \"POST\":\\n                raise HTTPException(405, \"Method not allowed (%s).\" % method)\\n\\n            # Parse the request\\n            try:\\n                length = int(env[\"CONTENT_LENGTH\"])\\n            except AttributeError:\\n                length = -1\\n            try:\\n                pr = codec.decode(env[\"wsgi.input\"].read(length))\\n            except codec.ParsingError as e:\\n                raise HTTPException(400, e.message)\\n\\n            # Find the remote proxy\\n            servers = self.__resolver.lookup(\\n                pr.realm,\\n                kpasswd=isinstance(pr, codec.KPASSWDProxyRequest)\\n            )\\n            if not servers:\\n                raise HTTPException(503, \"Can\\'t find remote (%s).\" % pr)\\n\\n            # Contact the remote server\\n            reply = None\\n            wsocks = []\\n            rsocks = []\\n            for server in map(urlparse.urlparse, servers):\\n                # Enforce valid, supported URIs\\n                scheme = server.scheme.lower().split(\"+\", 1)\\n                if scheme[0] not in (\"kerberos\", \"kpasswd\"):\\n                    continue\\n                if len(scheme) > 1 and scheme[1] not in (\"tcp\", \"udp\"):\\n                    continue\\n\\n                # Do the DNS lookup\\n                try:\\n                    port = server.port\\n                    if port is None:\\n                        port = scheme[0]\\n                    addrs = socket.getaddrinfo(server.hostname, port)\\n                except socket.gaierror:\\n                    continue\\n\\n                # Sort addresses so that we get TCP first.\\n                #\\n                # Stick a None address on the end so we can get one\\n                # more attempt after all servers have been contacted.\\n                addrs = tuple(sorted(filter(self.__filter_addr, addrs)))\\n                for addr in addrs + (None,):\\n                    if addr is not None:\\n                        # Bypass unspecified socktypes\\n                        if (len(scheme) > 1\\n                                and addr[1] != self.SOCKTYPES[scheme[1]]):\\n                            continue\\n\\n                        # Create the socket\\n                        sock = socket.socket(*addr[:3])\\n                        sock.setblocking(0)\\n\\n                        # Connect\\n                        try:\\n                            # In Python 2.x, non-blocking connect() throws\\n                            # socket.error() with errno == EINPROGRESS. In\\n                            # Python 3.x, it throws io.BlockingIOError().\\n                            sock.connect(addr[4])\\n                        except socket.error as e:\\n                            if e.errno != 115:  # errno != EINPROGRESS\\n                                sock.close()\\n                                continue\\n                        except io.BlockingIOError:\\n                            pass\\n                        wsocks.append(sock)\\n\\n                    # Resend packets to UDP servers\\n                    for sock in tuple(rsocks):\\n                        if self.sock_type(sock) == socket.SOCK_DGRAM:\\n                            wsocks.append(sock)\\n                            rsocks.remove(sock)\\n\\n                    # Call select()\\n                    timeout = time.time() + (15 if addr is None else 2)\\n                    reply = self.__await_reply(pr, rsocks, wsocks, timeout)\\n                    if reply is not None:\\n                        break\\n\\n                if reply is not None:\\n                    break\\n\\n            for sock in rsocks + wsocks:\\n                sock.close()\\n\\n            if reply is None:\\n                raise HTTPException(503, \"Remote unavailable (%s).\" % pr)\\n\\n            # Return the result to the client\\n            raise HTTPException(200, codec.encode(reply),\\n                                [(\"Content-Type\", \"application/kerberos\")])\\n        except HTTPException as e:\\n            start_response(str(e), e.headers)\\n            return [e.message]'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes.iloc[0]['code_before']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/latchset/kdcproxy.git/commit/f274aa6787cb8b3ec1cc12c440a56665b7231882'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes.iloc[0]['repo_url'] + '/commit/'+df_codes.iloc[0]['hash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes['commit_url'] = df_codes.apply(lambda x: x['repo_url'] + '/commit/'+x['hash'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_codes.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = counts['0']/counts['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = int(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert label to int\n",
    "df_codes['target'] = df_codes['target'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'flaw_lines' in df_codes.columns:\n",
    "    df_flaw_index = df_codes.apply(\n",
    "        lambda row: \",\".join([str(int(i) - int(row['start_line'])) for i in row['flaw_lines'].split(\",\")])\n",
    "                    if row['target'] == 1 else -1,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Update the flaw_index column in the DataFrame\n",
    "    df_codes['flaw_index'] = df_flaw_index\n",
    "else:\n",
    "    df_codes['flaw_index'] = -1\n",
    "    df_codes['flaw_lines'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Train set shape: (10735, 5)\n",
      "Validation set shape: (1342, 5)\n",
      "Test set shape: (1342, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "df_python_align = df_codes[['code_before', 'target', 'flaw_lines', 'flaw_index', 'commit_url']]\n",
    "df_python_align.columns = ['processed_func', 'target', 'flaw_line', 'flaw_line_index', 'commit_url']\n",
    "\n",
    "# Split the DataFrame into train and remaining\n",
    "train_df, remaining_df = train_test_split(df_python_align, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the remaining DataFrame into validation and test\n",
    "val_df, test_df = train_test_split(remaining_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting DataFrames\n",
    "print(\"Train set shape:\", train_df.shape)\n",
    "print(\"Validation set shape:\", val_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)\n",
    "\n",
    "train_df.to_csv(f\"/hpcfs/users/a1232991/Data/CVESingle/CVE{language}_train.csv\", index=None)\n",
    "val_df.to_csv(f\"/hpcfs/users/a1232991/Data/CVESingle/CVE{language}_val.csv\", index=None)\n",
    "test_df.to_csv(f\"/hpcfs/users/a1232991/Data/CVESingle/CVE{language}_test.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
