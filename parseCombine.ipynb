{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpcfs/users/a1232991/local/virtualenvs/llm/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\"Python\", \"TypeScript\", \"Java\", \"CS\", \"CCPP\", \"JavaScript\"]\n",
    "# languages = [\"C\", \"CPP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_name = {\"JavaScript\": \"JS\", \"Python\": \"PY\", \"TypeScript\": \"TS\", \"CCPP\": \"CCPP\", \"Java\": \"JAVA\", \"CS\": \"CS\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for codes in df['processed_func'].tolist():\n",
    "#     try:\n",
    "#         tokenizer.tokenize(codes)\n",
    "#     except:\n",
    "#         print(codes)\n",
    "#         break\n",
    "\n",
    "# token_lengths = df['processed_func'].apply(lambda x: len(tokenizer.tokenize(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine train val test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hpcfs/users/a1232991/local/virtualenvs/llm/lib/python3.9/site-packages/codetf/tree-sitter-prebuilts/Linux\n",
      "Python\n",
      "count    11060.000000\n",
      "mean       345.765371\n",
      "std        641.236997\n",
      "min          9.000000\n",
      "25%         70.000000\n",
      "50%        159.000000\n",
      "75%        375.000000\n",
      "max      14433.000000\n",
      "Name: processed_func, dtype: float64\n",
      "TypeScript\n",
      "count    1221.000000\n",
      "mean      158.694513\n",
      "std       363.288847\n",
      "min         2.000000\n",
      "25%        29.000000\n",
      "50%        60.000000\n",
      "75%       145.000000\n",
      "max      6026.000000\n",
      "Name: processed_func, dtype: float64\n",
      "Java\n",
      "count    10172.000000\n",
      "mean       246.674204\n",
      "std       1447.041160\n",
      "min          7.000000\n",
      "25%         41.000000\n",
      "50%         82.000000\n",
      "75%        217.000000\n",
      "max      95973.000000\n",
      "Name: processed_func, dtype: float64\n",
      "C#\n",
      "count     1600.000000\n",
      "mean       439.733750\n",
      "std       1201.278511\n",
      "min         12.000000\n",
      "25%         94.000000\n",
      "50%        201.000000\n",
      "75%        416.000000\n",
      "max      26012.000000\n",
      "Name: processed_func, dtype: float64\n",
      "C\n",
      "count     52835.000000\n",
      "mean        622.764701\n",
      "std        1764.828938\n",
      "min           9.000000\n",
      "25%         108.000000\n",
      "50%         241.000000\n",
      "75%         578.000000\n",
      "max      119340.000000\n",
      "Name: processed_func, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from codetf.code_utility.apex.apex_code_utility import ApexCodeUtility\n",
    "\n",
    "apex_code_utility = ApexCodeUtility()\n",
    "\n",
    "for lan in languages:\n",
    "    print(lan)\n",
    "    df_train = pd.read_csv(f'/hpcfs/users/a1232991/Data/CVESingle/CVE{lan}_train.csv')\n",
    "    df_val = pd.read_csv(f'/hpcfs/users/a1232991/Data/CVESingle/CVE{lan}_val.csv')\n",
    "    df_test = pd.read_csv(f'/hpcfs/users/a1232991/Data/CVESingle/CVE{lan}_test.csv')\n",
    "    df = pd.concat([df_train, df_val, df_test])\n",
    "\n",
    "    token_lengths = df['processed_func'].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "    print(token_lengths.describe())\n",
    "    # print(df.target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_target(row):\n",
    "    if row['target'] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = []\n",
    "val_sets = []\n",
    "test_sets = []\n",
    "\n",
    "for lan in languages:\n",
    "    df_train = pd.read_csv(f'/hpcfs/users/a1232991/Data/CVESingle/CVE{lan}_train.csv')\n",
    "    df_val = pd.read_csv(f'/hpcfs/users/a1232991/Data/CVESingle/CVE{lan}_val.csv')\n",
    "    df_test = pd.read_csv(f'/hpcfs/users/a1232991/Data/CVESingle/CVE{lan}_test.csv')\n",
    "    df_train['language'] = lan\n",
    "    df_val['language'] = lan\n",
    "    df_test['language'] = lan\n",
    "    # df_train['target'] = df_train['target'].apply(lambda x: )\n",
    "\n",
    "    train_sets.append(df_train)\n",
    "    val_sets.append(df_val)\n",
    "    test_sets.append(df_test)\n",
    "\n",
    "df_train = pd.concat(train_sets)\n",
    "df_val = pd.concat(val_sets)\n",
    "df_test = pd.concat(test_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all the above datasets\n",
    "df_train.to_csv('/hpcfs/users/a1232991/Data/CVESingle/CVECC_train.csv', index=None)\n",
    "df_test.to_csv('/hpcfs/users/a1232991/Data/CVESingle/CVECC_test.csv', index=None)\n",
    "df_val.to_csv('/hpcfs/users/a1232991/Data/CVESingle/CVECC_val.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python\n",
      "TypeScript\n",
      "Java\n",
      "CS\n",
      "CCPP\n",
      "JavaScript\n"
     ]
    }
   ],
   "source": [
    "train_sets = []\n",
    "val_sets = []\n",
    "test_sets = []\n",
    "\n",
    "for lan in languages:\n",
    "    print(lan)\n",
    "    sname = short_name[lan]\n",
    "    df_train = pd.read_csv(f'/hpcfs/users/a1232991/Data/CVESingle/CVE_{sname}/CVE{lan}_train.csv')\n",
    "    df_val = pd.read_csv(f'/hpcfs/users/a1232991/Data/CVESingle/CVE_{sname}/CVE{lan}_val.csv')\n",
    "    df_test = pd.read_csv(f'/hpcfs/users/a1232991/Data/CVESingle/CVE_{sname}/CVE{lan}_test.csv')\n",
    "\n",
    "    df_train['language'] = lan\n",
    "    df_val['language'] = lan\n",
    "    df_test['language'] = lan\n",
    "\n",
    "    train_sets.append(df_train)\n",
    "    val_sets.append(df_val)\n",
    "    test_sets.append(df_test)\n",
    "\n",
    "df_train = pd.concat(train_sets)\n",
    "df_val = pd.concat(val_sets)\n",
    "df_test = pd.concat(test_sets)\n",
    "\n",
    "# save all the above datasets\n",
    "df_train.to_csv(f'/hpcfs/users/a1232991/Data/CVESingle/CVEALL_train.csv', index=None)\n",
    "df_test.to_csv(f'/hpcfs/users/a1232991/Data/CVESingle/CVEALL_test.csv', index=None)\n",
    "df_val.to_csv(f'/hpcfs/users/a1232991/Data/CVESingle/CVEALL_val.csv', index=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
